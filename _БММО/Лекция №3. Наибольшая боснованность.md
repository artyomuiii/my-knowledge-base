## Лекция №3. Байесовские методы выбора моделей. Принцип наибольшей обоснованности.

Вероятностные модели:
* **дискриминантная:** 
$$
p(t, \theta|x) = p(t|x, \theta) p(\theta)
$$
* **генеративная:**
    (более общая)
$$p(t, x, \theta) = p(t, x|\theta) p(\theta) = p(t|x, \theta) p(x|\theta) p(\theta)
$$

Инференс в:
* классическом подходе:
$$
p(t_{test}|x_{test}, X_{tr}, T_{tr}) = p(t_{test}|x_{test}, \theta_{ML})
$$

* байесовском подходе:
    Ансамблирование по разным параметрам. Очень сильно позволяет повысить качество моделей.
$$
p(t_{test}|x_{test}, X_{tr}, T_{tr}) = \int p(t_{test}|x_{test}, \theta) p(\theta|X_{tr}, T_{tr}) d\theta
$$

---


Пусть нам даны несколько вероятностный моделей. Например, SVM, log-reg с $L_1$, log-reg с $L_2$ и т.д.

*Постановка задачи:*
Выбрать модель, наилучшую в некотором смысле.

Для этого могут применяться CV (очень! долго), информационные критерии (Акаики и т.д.) и т.д.
Мы в качестве метрики сравнения будем использовать **принцип наибольшей обоснованности**, который явл-ся мат. интерпретацией (*TODO забыл, выводилось ли это?*) **"Бритвы Оккама"** - *"не следует привлекать новые сущности без крайней на то необходимости".* Применительно к нашему случаю: выбираем наиболее простую модель, которая описывает данные.
Обос-ть и правдоподобие связаны обратной зав-тью: чем сложнее модель, тем сильнее можно увел-ть вер-ть пронаблюдать данные, и тем меньше вер-ть, что это наиболее простая описывающая данные модель.
**Правдоподобие (Evidence)** - это знаменатель в т-ме Байеса: $p(X)$.

Ещё один принцип, на котором основывается научный подход, это **критерий фальсифицируемости Поппера**, который гласит: *"знание научно, если его можно опровергнуть".* Аналогично сущ-ет мат. интерпретация через обос-ть: обос-ть модели, которая описывает все данные, стремится к 0.
Примеры НЕ научных знаний: *"на всё воля Божья"*, *"спецоперация идёт по плану"* и т.д.


---

*Пример:*
Данные о казнях в Америке. Статистика приводится по чёрным и белым. Необходимо ответить на вопрос: есть ли дискриминация? Для этого рас-ют разные вероятностные модели наказания, которе считают, что :
* нет никакой связи между расами;
* имеет место зав-ть от расы убийцы;
* имеет место зав-ть от расы жертвы;
* имеет место зав-ть и от расы жертвы, и от расы убийцы.

В итоге выбирается модель, у которой наибольшая обоснованность.
В данном примере также наблюдается **парадокс Симпсона.**

