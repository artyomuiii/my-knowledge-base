*Svetlana Illarionova, ...*
**ICCV ()** - #TODO 

#### Abstract
NN - это круто, решения на них основанные в большинстве областей CV дают SotA, однако для успешного обучения **нужны данные**. Качественные и в больших кол-вах. Особенно остро это ощущается в задачах [[Дистанционное зондирование Земли|дистанционного зондирования Земли (ДЗЗ)]] - детекция объектов и [[Семантическая сегментация|семантическая сегментация]]. Поэтому необходимы эффективные подходы для аугментации данных. В данной статье предлагается конвейр **object-based augmentation (OBA)**. Тестирование проводится на наборе данных для сегментации зданий с различными архитектурами CNN. Предложенный метод показывает свою состоятельность.

Аннотация на русском:
1. В последнее время нейронные сети активно используются, решения на их основе в большинстве областей компьютерного зрения показывают лучшие результаты, но для успешного обучения этим сложным моделям требуется много размеченных данных хорошего качества. Достаточно остро это ощущается в задачах дистанционного зондирования Земли, а именно в задачах детекции объектов и семантической сегментации.
2. Необходимо предложить эффективные подходы для качественной аугментации данных применительно к этой научной области.
3. В данной статье специально для решения задач ДЗЗ предлагается object-based augmentation (OBA) метод, который основан на обрезке изображений и их масок из размеченного датасета и вставке их на новые изображения фонов из неразмеченного датасета с применением базовых геометрических и цветовых аугментаций и наложением теней. Большинство этапов выполняется с некоторой заданной вероятностью, что делает новые данные ещё более разнообразными.
4. Данный метод действительно работает лучше существующих классических подходов к аугментации данных, что демонстрируется авторами в разнообразных поставленных ими экспериментах.
5. Применение данного метода позволит лучше решить уже существующие задачи, а также совершенно новые небольшие задачи, которые раньше решить не представлялось возможным из-за недостатка данных. Дальнейшее развитии подходов аугментации позволит сэкономить много сил и времени на разметке данных.

Аннотация на английском:
1. Recently, neural networks have been actively used, solutions based on them in most areas of computer vision show the best results, but for successful training of these complex models, a lot of marked-up data of good quality is required. This is quite acutely felt in the tasks of remote sensing of the Earth, namely in the tasks of object detection and semantic segmentation.
2. It is necessary to propose effective approaches for qualitative data augmentation in relation to this scientific field.
3. In this article, specifically for solving remote sensing problems, an object-based augmentation (OBA) method is proposed, which is based on cropping images and their masks from a marked dataset and inserting them onto new images of backgrounds from an unmarked dataset using basic geometric and color augmentation and shadow overlay. Most of the steps are performed with some given probability, which makes the new data even more diverse.
4. This method really works better than the existing classical approaches to data augmentation, which is demonstrated by the authors in a variety of experiments they have set up.
5. The use of this method will make it possible to better solve existing problems, as well as completely new small tasks that previously could not be solved due to lack of data. Further development of augmentation approaches will save a lot of effort and time on data markup.
#### 1. Introduction
*Идея:* обрезка объектов с исходных изображений с использованием их
масок и вставка их на новый фон.

Идея уже встречалась в других статьях, но новизна конкретно этой статьи - впервые применение к задаче ДЗЗ.

*Используемые архитектуры:* **U-Net**, **Feature Pyramid Network (FPN)**, **HRNet**

*Предложения, новизна:*
* предлагается метод аугментации OBA;
* производится тестирование и демонстрируется преимущество данного метода над другими методами аугментации;
* показывается возможность оптимизации параметров OBA для ещё лучших результатов;

*Код:* https://github.com/LanaLana/satellite_object_augmentation
#### 2. Related Works
Улучшение аугментаций может идти по двум направлениям: *image-based* (преобразует всё изображение целиком, например, геом. преобр-я) и *object-based* (работает с каждым объектом на изображении независимо).

#TODO дописать
Есть попытки применения GANов, 3D моделей и тд.
#### 3. Methodology
##### 3.1. Object-based augmentation
Требуются изображения, содержащие объекты (с масками) и фоновые изображения. Каждый объект имеет свой ID и пространственные координаты, извлечённые из файла `geojson` => объект можно вырезать и вставить на другой фон.
* Фоновые области подразделяются на 2 типа: из исходного набора данных и новые неразмеченные изображения для внесения разнообразия в данные.
* Объект и фон выбираются случайно: объект по предопределённым размерам вырезается с исходного изображения и с маски этого изображения. С таким же предопределённым размером режется и фон.
* С некоторой вероятностью применяются геометрические и цветовые аугментации к полученным промежуточным изображениям-обрезкам (аугментации реализованы в **Albumentations package** \[4\]). Все параметры трансформаций - по умолчанию, т.к. в других статьях поступают также.
   Весь список доступных преобразований:
   ![[Pasted image 20231031162941.png]]
* Трансформированный вырезанный объект накладывается на трансформированный фон и получается новое полноценное изображение.
* Кол-во объектов на новом изображении выбрано случайно из заданного диапазона, их наложения друг на друга запрещаются, каждому объекту добавляется настраиваемая (длина, интенсивность) тень для реалистичности изображения.

Общая схема конвейера преобразований:
![[Pasted image 20231031162722.png]]

Пример работы OBA:
![[Pasted image 20231031164211.png]]

Датасет **DOTA** с изображениями размера примерно 4000x4000 пикселей при низкой плотности представленности предметных объектов.
Данные ДЗЗ (также как и данные DOTA, только ещё больше) имеют очень большие пространственные характеристики => для того, чтобы скормить их CNN их нужно сначала порезать, но резать лишь бы как нельзя, нужно так, чтобы в crop-ах были целевые объекты. OBA умеет правильно вырезать с исходных данных ДЗЗ, используя координаты объектов.

Весь процесс генерации новой выборки выполняется во время обучения модели. Цель была обеспечить большее разнообразие без выделения памяти на хранение дополнительной выборки => все шаги OBA были реализованы в **загрузчике данных** и **генераторе**. Новые сгенерированные сэмплы также чередуются с оригинальными.

Итого, OBA включает в себя следующие опции:
* настраиваемое добавление теней;
* выбор кол-ва объектов на генерируемом изображении;
* выбор базового цвета и вер-ть геометрических преобразований;
* выбор фонового изображения;
* выбор вер-ти смешивания оригинальных и сгенерированных сэмплов.

Подходы для сравнения:
* `Baseline` - использует только базовые цветовые и геометрические аугментации;
* `Baseline_no_augm` - вообще без аугментаций;
* `OBA`;
* `OBA_no_augm` - применяет вырезку и вставку OBA без аугментаций;
* `OBA_no_shadow` - OBA без генерации теней;
* `OBA_no_background` - OBA без использования новых фонов.
##### 3.2. Optimization
Подбор гиперпараметров - это очень важно. Для этого использовалась **Optuna** с ранней обрезкой **MedianPruner**.

Рассматриваемые гиперпараметры:
* кол-во генерируемых объектов в пределах одного crop-а;
* вер-ть преобразования базового цвета;
* вер-ть применения OBA;
* вер-ть использования дополнительного фона(?).

Для этого исследования использовались 12 эпох и одинаковые валидационные данные для получения максимально эквивалентных критериев ранней обрезки.
#### 4. Experiments
Разработанный конвейер оценён на задаче семантической сегментации ДЗЗ, а именно сегментации зданий.
##### 4.1. Dataset
Датасет описан в \[33\].   
Этот набор данных был собран для оценки ущерба при ЧС и включал изображения до и после лесных пожаров в Калифорнии в 2017 году. Однако использовались только данные до события. Датасет охватывает округа Вентура и Санта-Роза (общая площадь ~580 га). Изображения с очень высоким разрешением по RGB для этого региона были доступны через **Digitalglobe** в рамках их программы открытых данных. Использовались 955 зданий из Вентуры для обучения и 226 для валидации, а для тестирования - 282 здания из Санта-Розы:
![[Pasted image 20231221151540.png]]
Маски объектов представлены как в растровом формате TIFF, так и
в векторном.

Пример изображения, которое использовалось для обучения:
![[Pasted image 20231221151703.png]]

В качестве дополнительного фона выбран датасет без целевых объектов с высоким разрешением из **Maxar serves** \[29\] (Калифорния). Из него вырезаются тестовые, валидационные и обучающие изображения общей площадью ~3000 га. В них входят различные типы растительного покрова: газоны, отдельные деревья, дороги и лесные массивы.
##### 4.2. Effect of the train dataset size
Были рассмотрены следующие подмн-ва обучающей выборки:
* весь набор данных;
* 2/3 набора данных;
* 1/3 набора данных.

Для каждого эксперимента использовался один и тот же набор валидационных данных. Для сокращённых наборов данных запускали модель на разных подмн-вах: 2 и 3 подмн-ва, соотв., для каждого из упомянутых размеров. Окончательные результаты для каждого размера были определены как средние значения.

Режимы обучения, на которых проводился эксперимент:
* `Baseline_no_augm`;
* `Baseline`;
* `OBA`.

[[#^35c753|Результаты]]

Также был проведен следующий эксперимент (претрен с аугментацией + fine-tune на ориг. данных):
1. Предварительно обучают модель, используя только что сгенерированные выборки для заранее определённого фикс. кол-ва эпох: 5, 10, 15 или 20;
2. Продолжают обучение, используя только исходные выборки для заранее определённого фикс. кол-ва эпох: 2, 4 или 8.

Т.о., получается 12 моделей, которые используют для обучения различные пропорции сгенерированных и оригинальных данных:
![[Pasted image 20231221154139.png]]
##### 4.3. Neural Networks Models And Training Details
* В качестве различных архитектур CNN рассмотрены **FPN** и **U-Net** с тремя размерами кодировщиков: **ResNet-18**, **ResNet-34**, **ResNet-50**. Также была обучена более современная **HR-Net** с **ResNet-101**. Все модели использовали веса, предобученные на **ImageNet**.
* Графический ускоритель: **GTX-1080Ti**
* Оптимизатор: [[RMSProp]] (подробнее см. в статье)
* 50 эпох со 100 шагами на эпоху и 30 шагов на проверку
* Батч: 30 с размером crop-а 128x128.
* Функция потерь: **бинарная кросс-энтропия**
   ![[Pasted image 20231222092459.png]]
   Где $N$ - кол-во пикселей истинной маски, $y$ - истинная маска, $\hat y$ - прогноз модели.
##### 4.4. Evaluation
Оценка производилась с помощью попиксельного **F1-score**, который хорошо работает с несбалансированными классами:
![[Pasted image 20231222094205.png]]
Где $TP$ - **True Positive**, $FP$ - **False Positive**, $FN$ - **False Negative**.

Для каждого эксперимента трижды запускалась модель CNN с разными случайными начальными значениями. Результаты усреднялись.
#### 5. Results and discussion
Результат эксперимента выше:
![[Pasted image 20231222095337.png]] ^35c753

Пример работы модели:
![[Pasted image 20231222095728.png]]

#STOP 
![[Pasted image 20231222100229.png]]

#### 6. Conclusion
#### References
4, 25, 29, 33, 35, 39, 42, 43, 53