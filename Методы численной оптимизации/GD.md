**GD** -  метод нахождения локального минимума или максимума функции с помощью движения вдоль градиента - метод первого порядка.

Решается задача минимизации эмпирического риска:
$$
Q(w)=\sum_{i=1}^{\ell} \mathscr{L}_{i}(w) \rightarrow \min _{w}
$$
$w^{(0)}:=$ начальное приближение; 
$w^{(t+1)}:=w^{(t)}-h \cdot \nabla Q\left(w^{(t)}\right), \quad \nabla Q(w)=\left(\frac{\partial Q(w)}{\partial w_{j}}\right)_{j=0}^{n}$,
где $h$ - градиентный шаг или темп обучения (**learning rate**)
$$
w^{(t+1)}:=w^{(t)}-h \sum_{i=1}^{\ell} \nabla \mathscr{L}_{i}\left(w^{(t)}\right)
$$

**Преимущества:**
* Гарантирует сходимость к локальному экстремуму (градиент около точки оптимума равен нулю гарантировано). *(TODO разве не может быть стационарной ситуации?)*

**Недостатки:**
* Очень долгое вычисление, т.к. приходится проходиться по всей выборке.

**Улучшения:**
* [[SGD]]