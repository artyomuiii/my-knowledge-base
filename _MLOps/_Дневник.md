___
...

1. 11.01.24 (1:32) - читал доку isort; обновлял `.pre-commit-config.yaml`; писал в `pyproject.toml` доп. настройки тулзов; установил `isort` в систему, в `VS Code` и прошёлся им по всему коду; заинсталил и запустил `pre-commit` на всех файлах; отрывками для всего вышеперечисленного пересматривал 2 сем.

2. 12.01.24 (1:43) - дописал файл `pyproject.toml`; нашёл в `isort` и `black` все опции и за что они отвечают; читал про работу утилиты `grep` (использовал её, чтобы понять сменились ли настройки в isort-конфиге); запушил текущие изменения в проект, перед этим выполнив все добавленные хуки `pre-commit`; создал и веду (здесь и далее) дневник в `Obsidian`; для всего отрывками пересматривал 2 сем; **получил неуд. по предмету** => пойду на пересдачу и нормально разберусь.

**Неделя 5.2 - 15:44**
___
**Подготовка к пересдаче**
1. 19.02.24|Пн (1:49) - кратко повторил конспект лекции №2 и записанной части семинара №2; смотрел "внахлёст" с небольшим повтором семинар №2 (не полностью); изучил частые ошибки задания №1; дополнил `README.md`; в коде сделал полный `train` и не полный `infer`;  добавил `if name main` в код;
2. 21.02.24|Ср (1:13) - досмотрел семинар №2 про Github (и частично про Gitlab) Actions; добавил в проект голую папку `.github/workflows`; начал смотреть лекцию №4 (лекцию и семинар №3 пропустил).
3. 22.02.24|Чт (0:19) - смотрел лекцию №4;
4. 23.02.24|Пт (7:22) - досмотрел лекцию №4; посмотрел половину семинара №4; написал `infer.py`; прикрутил `DVC`; прикрутил `hydra`; посмотрел полтора часа семинара №5;

**Неделя 6.4 - :**
___
**Всего за семестр времени выделено - 25:16**
**Всего на подготовку к пересдаче времени выделено - :**
*(обновляется раз в неделю)*
___
*План:* сделать первые два задания (т.е. доделать 1ое задание и сделать 2ое)
___
*Материалы:*
Homework 2

Следующий этап развития проекта это добавление системы управления данными, в нашем случае это dvc, конфигурации экспериментов на основе hydra, а также логирование на основе mlflow. Для тех, кто делает проекты с нейросетями будет плюсом использование фреймворка для обучения модели (catalyst, lightning, hugging face). Напоследок сконфигурировать простой сервер предсказаний модели используя mlflow models.

1. DVC
Для dvc в качестве бекенда проще и доступнее всего использовать гугл диск (проверьте, что папка доступна по ссылке на чтение всем, иначе мы не сможем проверить), можно использовать и любой другой бекенд, но тут возникает такой же вопрос с доступностью.
Скачивание данных с помощью dvc необходимо встроить в имеющиеся команды train и infer, для этого у dvc есть python api (на крайний случай можно дёрнуть CLI).

2. Hydra
Переведите основные гиперпараметры препроцессинга, обучения и постпроцессинга в yaml конфиги hydra. Сами конфиги лучше всего расположить в папке configs в корне репозитория.

3. Logging
Необходимо добавить логирование ваших основных метрик и функций потерь (всего не менее 3 графиков). Также в эксперимент записывать использованные гиперпараметры и версию кода (git commit id). Считайте, что сервер mlflow уже поднят, его адрес добавьте в поле конфига.

4. Inference
Экспортируйте модель в onnx и добавьте команду run_server (либо в fire, либо отдельным .py файлом), в которой используя mlflow models запустите инференс модели из onnx файла.

Результат работы оформите в виде тега с названием ‘hw2’ в git репозитории.

Дедлайн (жёсткий): вскр, 3 декабря, 23.59 по Мск

Репозиторий у вас остаётся прежний, поэтому формы заполнять не нужно, достаточно создать тег в git репозитории. Для тех, кто ещё не отправлял нам адрес репы - это можно сделать в той же форме (https://docs.google.com/forms/d/e/1FAIpQLSfLlurK3Z3KQNnobvvKD8ObZ5NVdaiwf57jaVVHnHoautivpw/viewform?usp=sf_link)




лекция 7 и сем 7 вроде нахуй не нужны
лекция6 - работа с mlflow, частично надо
сем6 - lightning и логирование, вроде надо
лекция5 - можно скип наверн, просто рассказывает че есть
сем 4 - самое важное
Лекции все особо не нужны как будто


По итогу просмотра первой домашней работы были выявлены типичные ошибки (список ниже).
Для успешного выполнения второго задания нужно их исправить.
Для повышения качества жизни проверяющих (и получения отличной оценки) рекомендуется также выполнить пункты из раздела “желательно”.

Что нужно исправить:
* Заполнить файл README, в нём объяснить, какую задачу вы решаете (у каждого что-то своё, так что нам нужно это знать)
* Нельзя объявлять переменные (кроме констант) на верхнем уровне файла (не внутри функции или класса). Это можно делать только внутри классов, функций или под if name main.
* Под вызовом if name main вызывать ровно одну функцию (можно её назвать main или как-то ещё), а не писать всю логику непосредственно под if-ом
* warnings.filterwarnings("ignore") - это исчадье сатаны. Никогда не делайте этого в продакшен любых проектах. Это огромный задел на отстреливание себе ноги. Люди пишут предостережения для вас, но вы же умнее каких-то там авторов библиотек!
* Используйте реальные данные. Нельзя использовать сгенерированные данные.
* Импорты из вашего проекта делайте либо локальными (через точку, например как тут (https://github.com/v-goncharenko/mimics/blob/master/mimics/classifiers.py#L16)), либо глобальными (когда начинаете с названия вашего пакета, вам это пока скорее всего не нужно, проще первый вариант)
* Нельзя сохранять данные в гит!!!!!!!!!!!!! То есть файлы .json, .csv, .h5 и проч. То же касается файлов натренированных моделей (.cbm, .pth, .xyz, etc). Я об этом говорил на лекциях, более того, сейчас вы даже знаете, как это делать правильно (через dvc). Нужно удалить все данные из гита.
* Некоторым с первого раза не понятно: ДВА ФАЙЛА - train.py и infer.py, не всё в одном
* Назвать питон пакет (aka папка с вашим кодом) по правилам питона (snake_case), а не как попало (e.g. MYopsTools)
* Используйте дефолтный .gitignore для Питона (не пустой), его дополняйте необходимыми вам путями. Дефолтный конфиг гуглится и даже предлагается вам гитхабом при создании репозитория.
* Запустить таки pre-commit run -a и убедиться, что он не красный
* Файлы с кодом называются в snake_case, не в CamelCase (e.g. Dataset.py)
* Репозиторий должен быть виден. Скрытые (приватные) репозитории оцениваются в 0 баллов.

Что делать желательно:
* Использовать fire вместо argparse
* Гит репозитории как правило называются в log-case (то есть слова разделяются дефисами), а не в CamelCase
* Сделать одну входную точку commands.py, где вызывать соответствующие функции из файлов
* Пересесть с иглы процедурного программирования (когда вы объявляете только функции) на ООП (aka классы).
* Для выполнения предыдущего пункта сначала нужно осмелиться создать больше двух файлов с кодом в папке (например вынести туда функции и импортировать их из этого пошеренного файла)
* Не делайте однобуквенные переменные, как будто в школе сидим программируем, ей богу…
* Конфиги лучше хранить не в json, а в yaml (это всё равно понадобится для Гидры)
* Используйте pathlib вместо os.path - важа жизнь заиграет совершенно другими красками
* Никто не называет папку с кодом src в Питоне… пожалуйста, не делайте так, это ничего хорошего в вашу жизнь не добавляет
* Не стоит все ваши функции и классы класть исключительно в utils - это получается какая-то свалка
